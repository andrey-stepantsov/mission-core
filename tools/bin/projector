#!/usr/bin/env python3
import argparse
import os
import sys
import subprocess
import json
import shutil
import time
import threading
import shlex
import tempfile

HOLOGRAM_DIR = "hologram"
OUTSIDE_WALL_DIR = "outside_wall"
CONFIG_FILE = ".hologram_config"

def run_command(cmd, shell=False, capture_stderr=True):
    """Runs a shell command and returns stdout."""
    try:
        stderr_dest = subprocess.PIPE if capture_stderr else sys.stderr
        result = subprocess.run(cmd, shell=shell, check=True, stdout=subprocess.PIPE, stderr=stderr_dest, text=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        # Check if stderr is just noise (warnings)
        err_msg = e.stderr if e.stderr else ""
        lines = err_msg.splitlines()
        real_errors = [l for l in lines if not (l.startswith("Warning:") or "setlocale" in l)]
        
        if real_errors:
            print(f"Error running command: {cmd}")
            print(f"Stderr: {err_msg}")
        elif not capture_stderr:
             # If we weren't capturing, typically means interactive or we don't care about output unless failed
            print(f"Command failed with exit code {e.returncode}: {cmd}")
            
        raise e  # Re-raise so caller handles flow

def load_config():
    # print("DEBUG: Entering load_config")
    current = os.path.abspath(os.getcwd())
    while True:
        candidate = os.path.join(current, CONFIG_FILE)
        if os.path.exists(candidate):
            with open(candidate, 'r') as f:
                return json.load(f)
        
        parent = os.path.dirname(current)
        if parent == current:
            break
        current = parent
        
    print("Error: Hologram not initialized (Config not found). Run 'projector init <host>' first.")
    sys.exit(1)

def save_config(config):
    # Always save to CWD or explicit root?
    # For now, save to CWD as that's usually init root
    with open(CONFIG_FILE, 'w') as f:
        json.dump(config, f, indent=4)


def do_init(args):
    """Initializes the hologram environment."""
    host_target = args.host_target
    
    # Support user@host:path syntax
    if ":" in host_target:
        parts = host_target.split(":", 1)
        host_target = parts[0]
        # Only override remote_root if not explicitly provided
        if not args.remote_root or args.remote_root == ".":
            remote_root = parts[1]
        else:
            remote_root = args.remote_root
    else:
        remote_root = args.remote_root
        
    remote_root = remote_root.rstrip("/") if remote_root else "."
    
    print(f"Initializing Hologram for host: {host_target} (Root: {remote_root})")
    
    os.makedirs(HOLOGRAM_DIR, exist_ok=True)
    os.makedirs(OUTSIDE_WALL_DIR, exist_ok=True)
    
    config = {
        "host_target": host_target,
        "remote_root": remote_root
    }
    save_config(config)
    print("Hologram initialized.")
    
    # 4. Launch The Tower (Observability)
    print("Launching The Tower (Remote Watcher)...")
    
    # Use explicit remote root to find launch_tower
    # Check for remote_mission_root
    config_data = load_config() # Reload or pass args? do_init calls save_config just before. 
    # Just use dictionary logic
    remote_mission_root = config.get("remote_mission_root")
    if remote_mission_root:
         mission_root = remote_mission_root
    else:
         mission_root = f"{remote_root}/.mission"
         
    tower_script = f"{mission_root}/tools/bin/launch_tower"
    
    # Fallback logic if root is '.', try typical locations
    if remote_root == "." and not remote_mission_root:
         tower_cmd = (
            "if [ -f .mission/tools/bin/launch_tower ]; then ./.mission/tools/bin/launch_tower; "
            "elif [ -f /mission/tools/bin/launch_tower ]; then /mission/tools/bin/launch_tower; "
            "else echo 'Tower script not found'; fi"
        )
    else:
        tower_cmd = f"if [ -f {tower_script} ]; then {tower_script}; else echo 'Tower script not found at {tower_script}'; fi"
    
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]

    run_command(["ssh"] + ssh_opts + [host_target, f"unset HISTFILE; {tower_cmd}"], capture_stderr=False)

    # 5. Deploy VSCode Configuration
    deploy_vscode_config(remote_root)
    
    # 6. Verify System Headers (Proactive Suggestion)
    sys_includes = config.get("system_includes", [])
    if not sys_includes:
        print("\n‚ö†Ô∏è  Suggestion: Run 'projector repair-headers' to enable full IntelliSense.")
        print("   This syncs system headers (e.g. stdio.h) which are missing by default.")

def deploy_vscode_config(remote_root, template_dir=None):
    """Deploys VSCode configuration templates if they exist."""
    print("Deploying VSCode configuration...")
    
    # Try to find templates in local .mission first (if sideloaded)
    # The projector script is in .mission/tools/bin/projector
    # So templates should be in .mission/templates/vscode
    
    if not template_dir:
        script_dir = os.path.dirname(os.path.realpath(__file__))
        # script_dir = .../.mission/tools/bin
        mission_root = os.path.dirname(os.path.dirname(os.path.dirname(script_dir)))
        # mission_root = .../.mission (if running from source) or just use relative if trustworthy
        
        # More robust finding strategy:
        # 1. Check relative to script location
        template_src = os.path.join(script_dir, "../../templates/vscode")
        
        if not os.path.exists(template_src):
            # 2. Check CWD/.mission (setup scenario)
            template_src = os.path.join(os.getcwd(), ".mission", "templates", "vscode")
    else:
        template_src = template_dir
        
    if os.path.exists(template_src):
        target_vscode = os.path.join(os.getcwd(), ".vscode")
        os.makedirs(target_vscode, exist_ok=True)
        
        for item in os.listdir(template_src):
            s = os.path.join(template_src, item)
            d = os.path.join(target_vscode, item)
            if os.path.isfile(s):
                if not os.path.exists(d):
                    shutil.copy2(s, d)
                    print(f"  Created {item}")
                else:
                    # Smart Merge for JSON files
                    if item.endswith(".json"):
                        try:
                            with open(s, 'r') as f_src:
                                template_data = json.load(f_src)
                            
                            try:
                                with open(d, 'r') as f_dst:
                                    existing_data = json.load(f_dst)
                            except json.JSONDecodeError:
                                # If existing file is corrupt or empty, overwrite?
                                # Safer to backup and copy
                                print(f"  Warning: Existing {item} is invalid JSON. Backing up and overwriting.")
                                shutil.copy2(d, d + ".bak")
                                shutil.copy2(s, d)
                                continue

                            merged = False
                            
                            # Specific Merge Logic
                            # 1. settings.json: merge clangd.arguments
                            if item == "settings.json":
                                # Merge clangd.arguments list (append unique?) or overwrite?
                                # Template is usually critical for correct Clangd operation.
                                # Let's ensure our args are present.
                                tmpl_args = template_data.get("clangd.arguments", [])
                                exist_args = existing_data.get("clangd.arguments", [])
                                
                                # If existing is missing keys, add them
                                for k, v in template_data.items():
                                    if k not in existing_data:
                                        existing_data[k] = v
                                        merged = True
                                        
                                # Force critical defaults?
                                if "clangd.arguments" in template_data:
                                    # Ensure critical flags exist
                                    current_set = set(exist_args)
                                    for arg in tmpl_args:
                                        if arg not in current_set:
                                            exist_args.append(arg)
                                            merged = True
                                    existing_data["clangd.arguments"] = exist_args
                                    
                            # 2. c_cpp_properties.json: merge configurations
                            elif item == "c_cpp_properties.json":
                                # Append 'Mission Config' if not present
                                tmpl_configs = template_data.get("configurations", [])
                                exist_configs = existing_data.get("configurations", [])
                                
                                exist_names = {c.get("name") for c in exist_configs}
                                for cfg in tmpl_configs:
                                    if cfg.get("name") not in exist_names:
                                        exist_configs.insert(0, cfg) # Prepend to make default?
                                        merged = True
                                existing_data["configurations"] = exist_configs
                                
                            else:
                                # Generic shallow merge: add missing keys
                                for k, v in template_data.items():
                                    if k not in existing_data:
                                        existing_data[k] = v
                                        merged = True
                                        
                            if merged:
                                with open(d, 'w') as f_dst:
                                    json.dump(existing_data, f_dst, indent=4)
                                print(f"  Merged configuration into {item}")
                            else:
                                print(f"  Skipped {item} (already up to date)")
                                
                        except Exception as e:
                            print(f"  Warning: Failed to merge {item}: {e}")
                    else:
                        print(f"  Skipped {item} (already exists)")
    else:
        print("  Warning: VSCode templates not found.")



def update_local_compile_db(context, dependencies=None):
    """Updates the unified local compile_commands.json with rewritten paths."""
    if not context:
        return

    config = load_config()
    remote_root = config.get('remote_root', '.')
    
    # Paths (Absolute Local)
    # We use os.getcwd() because hologram/outside_wall are in CWD where projector runs
    cwd = os.getcwd()
    hologram_abs = os.path.join(cwd, HOLOGRAM_DIR)
    outside_wall_abs = os.path.join(cwd, OUTSIDE_WALL_DIR)
    
    # 1. Rewrite Directory
    # context['directory'] is the remote build directory.
    # We map this to hologram structure.
    remote_dir = context.get('directory') or ''
    if remote_root and remote_dir.startswith(remote_root):
        rel_dir = os.path.relpath(remote_dir, remote_root)
        local_dir = os.path.join(hologram_abs, rel_dir)
    else:
        # If build dir is outside remote root (weird), fall back to hologram root
        local_dir = hologram_abs
        
    # 2. Rewrite File
    # context['file'] is remote absolute path
    remote_file = context.get('file') or ''
    if remote_root and remote_file.startswith(remote_root):
        rel_file = os.path.relpath(remote_file, remote_root)
        local_file = os.path.join(hologram_abs, rel_file)
    else:
        # If file is outside (e.g. system header?), we can't really edit it.
        # But auto_ghost usually targets files in repo.
        local_file = remote_file
        
    # 3. Rewrite Arguments
    # Rewrite -I /abs/path -> -I .../outside_wall/abs/path
    args = context.get('arguments')
    
    # Fallback: if 'arguments' is missing, parse 'command' string
    if not args:
        cmd_str = context.get('command') or context.get('cmd_str')
        if cmd_str:
            import shlex
            # On remote linux, arguments might be quoted, shlex.split should handle it
            args = shlex.split(cmd_str)
            
    args = args or []
    new_args = []
    
    i = 0
    while i < len(args):
        arg = args[i]
        
        # Handle -I /path
        if arg.startswith("-I") or arg.startswith("-L") or arg == "-isystem":
            # Check if it's a flag + value or separated
            flag = arg
            value = None
            consumed_next = False
            
            if arg == "-isystem":
                 if i + 1 < len(args):
                    value = args[i+1]
                    consumed_next = True
            elif len(arg) > 2:
                # -I/path
                flag = arg[:2]
                value = arg[2:]
            else:
                # -I /path
                 if i + 1 < len(args):
                    value = args[i+1]
                    consumed_next = True
            
            if value and value.startswith("/"):
                # Rewrite to outside_wall
                # /opt/foo -> .../outside_wall/opt/foo
                mapped_path = os.path.join(outside_wall_abs, value.lstrip("/"))
                
                # Check if we should enforce mapping or keep original?
                # Ideal: if exists locally, map it.
                if os.path.exists(mapped_path):
                     value = mapped_path
                else:

                     # If not mapped, do we keep original? 
                     # Current logic: we probably want to create the entry anyway?
                     # No, logic below (lines 240+) APPENDS to new_args ONLY IF we append `value`.
                     # If we don't update `value` here, we might just keep the original absolute path?
                     # Wait. The original code did: `if os.path.exists(mapped_path): value = mapped_path`.
                     # If NOT exists, `value` stays original absolute path `/repos/...`.
                     # BUT then compile_commands.json has `/repos/...`. 
                     # Clangd local sees `/repos/...`.
                     # /repos does not exist locally. So Clangd ignores it.
                     # So effective result: dropped.
                     pass
                
                if consumed_next:
                    new_args.append(flag)
                    new_args.append(mapped_path)
                    i += 2
                else:
                    new_args.append(f"{flag}{mapped_path}")
                    i += 1
                continue
                
        new_args.append(arg)
        i += 1
        
    # 3b. Inject Dependency Includes
    if dependencies:
        include_dirs = set()
        system_dirs = set()
        
        for dep in dependencies:
            if not dep.startswith("/"):
                continue
                
            # Map to outside_wall
            rel_dep = dep.lstrip("/")
            local_dep = os.path.join(outside_wall_abs, rel_dep)
            local_dep_dir = os.path.dirname(local_dep)
            
            # Heuristic: /usr, /opt, /lib are likely system
            if dep.startswith("/usr") or dep.startswith("/opt") or dep.startswith("/lib"):
                system_dirs.add(local_dep_dir)
            else:
                include_dirs.add(local_dep_dir)
                
        # Append new flags
        for d in sorted(list(include_dirs)):
            new_args.append(f"-I{d}")
            
        for d in sorted(list(system_dirs)):
            new_args.append(f"-isystem")
            new_args.append(d)

    # 4. Inject Missing System Headers (Global Config)
    system_includes = config.get("system_includes", [])
    if system_includes:
        existing_paths = set()
        # Scan current new_args for existing -isystem paths to avoid dupes
        for i in range(len(new_args)):
             if new_args[i] == "-isystem" and i+1 < len(new_args):
                  existing_paths.add(new_args[i+1])
             elif new_args[i].startswith("-isystem"):
                  existing_paths.add(new_args[i][8:])
                  
        for sys_inc in system_includes:
             # Rewrite to outside_wall
             mapped = os.path.join(outside_wall_abs, sys_inc.lstrip("/"))
             if mapped not in existing_paths:
                  new_args.append("-isystem")
                  new_args.append(mapped)
        
    entry = {
        "directory": local_dir,
        "file": local_file,
        "arguments": new_args
    }
    
    # 4. Upsert into compile_commands.json
    db_path = os.path.join(hologram_abs, "compile_commands.json")
    db = []
    if os.path.exists(db_path):
        try:
            with open(db_path, 'r') as f:
                db = json.load(f)
        except:
             pass
             
    # Remove existing entry for this file
    db = [e for e in db if e.get("file") != local_file]
    db.append(entry)
    
    with open(db_path, 'w') as f:
        json.dump(db, f, indent=2)
        
    print(f"Updated compile_commands.json for {os.path.basename(local_file)}")
    
    # 5. Check System Headers Status (Verification)
    # We check if we have any -isystem flags in new_args
    has_system_headers = any(a == "-isystem" or a.startswith("-isystem") for a in new_args)
    
    if not has_system_headers and not config.get("system_includes"):
        print("‚ö†Ô∏è  Warning: System headers not synced (missing in config).")
        print("   IntelliSense may be incomplete (e.g. <stdio.h>).")
        print("   Run 'projector repair-headers' to fix.")
        
    elif has_system_headers:
        # Verify they actually exist
        missing_sys = []
        for i in range(len(new_args)):
             val = None
             if new_args[i] == "-isystem" and i+1 < len(new_args):
                  val = new_args[i+1]
             elif new_args[i].startswith("-isystem"):
                  val = new_args[i][8:]
             
             if val and val.startswith(outside_wall_abs) and not os.path.exists(val):
                  missing_sys.append(val)
                  
        if missing_sys:
             print(f"‚ö†Ô∏è  Warning: {len(missing_sys)} system header paths are missing locally.")
             print("   Run 'projector repair-headers' to re-sync.")



def do_pull(args):
    """Pulls a file from the host."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    
    input_path = args.file
    
    # Resolve Remote Path
    if input_path.startswith("/"):
        remote_path = input_path
        # For absolute paths, we store them as full structure
        rel_path = input_path.lstrip("/")
    else:
        # For relative paths, prepend remote_root
        remote_path = f"{remote_root}/{input_path}".replace(os.path.sep, "/")
        rel_path = input_path

    print(f"Pulling {remote_path} from {host}...")
    
    # 1. Verify file exists on host
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
    try:
        run_command(["ssh"] + ssh_opts + [host, f"unset HISTFILE; test -f {remote_path}"])
    except subprocess.CalledProcessError:
        print(f"Error: File '{remote_path}' not found on remote host.")
        sys.exit(1)
    
    # 2. Rsync file to hologram/
    local_dest = os.path.join(HOLOGRAM_DIR, rel_path)
    os.makedirs(os.path.dirname(local_dest), exist_ok=True)
    
    rsync_cmd = ["rsync", "-az", "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null", f"{host}:{remote_path}", local_dest]
    run_command(rsync_cmd)
    print(f"Synced to {local_dest}")

    # 2b. Enforce Overlay: Hide from Outside Wall
    # If the file exists in outside_wall, we must remove it so the hologram takes precedence.
    wall_dest = os.path.join(OUTSIDE_WALL_DIR, rel_path)
    if os.path.exists(wall_dest):
        try:
            # Ensure parent is writable if needed
            parent_dir = os.path.dirname(wall_dest)
            if not os.access(parent_dir, os.W_OK):
                 try:
                     os.chmod(parent_dir, 0o755)
                 except: 
                     pass
            
            os.remove(wall_dest)
            print(f"üëª Ghosted (hidden) {wall_dest} from outside_wall")
        except OSError as e:
            print(f"Warning: Failed to hide {wall_dest} from outside_wall: {e}")
    
    # 3. Real Auto-Ghost (Dependency Syncing)
    print("Running Auto-Ghost logic...")
    
    # Use remote_root if available to find auto_ghost
    # We loaded config at start of do_pull
    remote_root = config.get('remote_root', '.')
    remote_mission_root = config.get('remote_mission_root')
    
    if remote_mission_root:
        auto_ghost_bin = f"{remote_mission_root}/tools/bin/auto_ghost"
    # If remote_root is absolute, try it first
    elif remote_root.startswith("/"):
        auto_ghost_bin = f"{remote_root}/.mission/tools/bin/auto_ghost"
    else:
        # Fallback to dynamic discovery
        auto_ghost_bin = "$(git rev-parse --show-toplevel 2>/dev/null || echo '.')/.mission/tools/bin/auto_ghost"
        
    # Improved discovery: Try project tool, then global tool
    # Improved discovery: Try project tool
    cmd_ghost = (
        f"ghost_bin=\"{auto_ghost_bin}\"; "
        f"if [ ! -f \"$ghost_bin\" ]; then echo 'Error: Auto-Ghost not found at $ghost_bin'; exit 1; fi; "
        f"cd $(dirname {remote_path}) && $ghost_bin --full {remote_path}"
    )
    
    if args.flags:
        # Safe quoting for the remote shell
        safe_flags = shlex.quote(args.flags)
        # Use = to ensure argparse doesn't confuse the value with a flag
        cmd_ghost += f" --flags={safe_flags}"
    
    compile_context = None
    dependencies = []
    
    try:
        json_output = run_command(["ssh"] + ssh_opts + [host, f"unset HISTFILE; {cmd_ghost}"], capture_stderr=False)
        data = json.loads(json_output)
        

        # Handle both old (list) and new (dict) formats for backward compatibility
        if isinstance(data, list):
            dependencies = data
        elif isinstance(data, dict):
            dependencies = data.get("dependencies", [])
            compile_context = data.get("compile_context")
            
            # Context Selection Logic
            if compile_context and "candidates" in compile_context:
                candidates = compile_context["candidates"]
                
                # If we have multiple candidates and no flags were used (or even if they were, but still vague)
                # Check for ambiguity
                if len(candidates) > 1:
                     # Interactive Mode: If TTY, ask user
                     if sys.stdin.isatty() or os.environ.get("PROJECTOR_INTERACTIVE") == "1":
                         print(f"\n‚ö†Ô∏è  Ambiguous compilation context found for {os.path.basename(input_path)}.")
                         print(f"   (Found {len(candidates)} candidates)")
                         print("   Multiple build targets define this file. Please select the correct context:")
                         
                         choices = []
                         # 1. Parse all candidates to sets of flags
                         cand_flags = []
                         import shlex
                         
                         for cand in candidates:
                             cmd = cand.get("cmd_str") or cand.get("command") or ""
                             # Simple split often enough, but careful with quotes
                             try:
                                 flags = set(shlex.split(cmd))
                             except:
                                 flags = set(cmd.split()) # Fallback
                             cand_flags.append(flags)
                             
                         # 2. Find Intersection (Common Flags)
                         if cand_flags:
                             common_flags = set.intersection(*cand_flags)
                         else:
                             common_flags = set()
                             
                         # 3. Display Diff
                         for idx, cand in enumerate(candidates):
                             flags = cand_flags[idx]
                             diff = flags - common_flags
                             
                             diff_str = " ".join(sorted(list(diff)))
                             if not diff_str:
                                 diff_str = "(Identical to others)"
                                 
                             # limit length
                             if len(diff_str) > 120:
                                 diff_str = diff_str[:117] + "..."
                                 
                             print(f"   [{idx+1}] {diff_str}")
                         
                         print(f"   [A] All of the above (Merged - Experimental)")
                         print(f"   [C] Cancel")
                         
                         try:
                             sel = input("\nSelect Context (1, 2, ..., A, C) [1]: ").strip()
                             if not sel: sel = "1"
                             
                             if sel.lower() == 'c':
                                 print("Selection cancelled.")
                                 sys.exit(0)
                             elif sel.lower() == 'a':
                                 print("Merging all candidates not yet supported. Using #1.")
                                 compile_context = candidates[0]
                             else:
                                 try:
                                     idx = int(sel) - 1
                                     if 0 <= idx < len(candidates):
                                         compile_context = candidates[idx]
                                         print(f"Selected candidate #{idx+1}")
                                     else:
                                          print(f"Invalid index. Defaulting to #1.")
                                          compile_context = candidates[0]
                                 except ValueError:
                                     print(f"Invalid input. Defaulting to #1.")
                                     compile_context = candidates[0]
                                     
                         except KeyboardInterrupt:
                             print("\nSelection cancelled.")
                             sys.exit(0)
                     else:
                        print(f"‚ö†Ô∏è  Ambiguous compilation context found for {os.path.basename(input_path)}.")
                        print(f"   Defaulting to Candidate #1. Use --flags to refine selection.")
                        print("")
                        print(f"   Options:")
                        
                        # 1. Parse all candidates to sets of flags
                        cand_flags = []
                        import shlex
                        
                        for cand in candidates:
                            cmd = cand.get("cmd_str") or cand.get("command") or ""
                            # Simple split often enough, but careful with quotes
                            try:
                                flags = set(shlex.split(cmd))
                            except:
                                flags = set(cmd.split()) # Fallback
                            cand_flags.append(flags)
                            
                        # 2. Find Intersection (Common Flags)
                        if cand_flags:
                            common_flags = set.intersection(*cand_flags)
                        else:
                            common_flags = set()
                            
                        # 3. Display Diff
                        for idx, cand in enumerate(candidates):
                            flags = cand_flags[idx]
                            diff = flags - common_flags
                            
                            # Filter out boring stuff if empty diff?
                            # Diff might include compiler binary, output file etc if they differ (unlikely for binary)
                            # Let's just show sorted diff
                            
                            diff_str = " ".join(sorted(list(diff)))
                            if not diff_str:
                                diff_str = "(Identical to others)"
                                
                            # limit length
                            if len(diff_str) > 120:
                                diff_str = diff_str[:117] + "..."
                                
                            print(f"   {idx+1}. {diff_str}")
                        print("")
            
    except Exception as e:
        print(f"Warning: Auto-Ghost failed or returned invalid data: {e}")

    print(f"Auto-Ghost found {len(dependencies)} implicit dependencies.")
    
    # MOVED: update_local_compile_db(compile_context, dependencies) to after sync

    # Step 3b: Batch Sync Dependencies to Outside Wall
    if dependencies:
        valid_deps = [d for d in dependencies if d.startswith("/")]
        
        if valid_deps:
            print(f"  Ghosting {len(valid_deps)} dependencies (Batch Optimized)...")
            
            # 1. Prepare Permissions (Write Access)
            for dep in valid_deps:
                rel = dep.lstrip("/")
                local = os.path.join(OUTSIDE_WALL_DIR, rel)
                if os.path.exists(local):
                     try:
                         os.chmod(local, 0o644)
                     except: pass
            
            # 2. Create Temp List
            with tempfile.NamedTemporaryFile(mode='w', delete=False) as tmp:
                tmp_path = tmp.name
                for dep in valid_deps:
                    tmp.write(dep + "\n")
            
            # 3. Batch Rsync
            # Sync from host root "/" to OUTSIDE_WALL_DIR using the file list
            rsync_cmd = [
                "rsync", "-az", 
                "--files-from", tmp_path,
                "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null", 
                f"{host}:/", 
                OUTSIDE_WALL_DIR
            ]
            
            try:
                run_command(rsync_cmd)
            except Exception as e:
                print(f"  Batch ghosting failed: {e}")
            finally:
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)

            # 4. Enforce Read-Only
            for dep in valid_deps:
                rel = dep.lstrip("/")
                local = os.path.join(OUTSIDE_WALL_DIR, rel)
                if os.path.exists(local):
                     try:
                         os.chmod(local, 0o444)
                     except: pass
    
    # Step 4: Update local compile database (AFTER syncing dependencies)
    # Step 4: Update local compile database (AFTER syncing dependencies)
    # CHANGED: Skip headers (they are not compilation units in DB)
    is_header = remote_path.endswith('.h') or remote_path.endswith('.hpp') or \
                remote_path.endswith('.hh') or remote_path.endswith('.hxx')
                
    if compile_context and not is_header:
        # CRITICAL: Override the file path to match the requested file (e.g. header)
        # because auto_ghost may have returned context for a sibling source file.
        compile_context['file'] = remote_path
        
        # DEBUG: Inspect context
        # import json # REMOVED
        # Removed full dump as it might be large, just keys and null check


        print(f"Updating compile_commands.json for {args.file}")
        update_local_compile_db(compile_context, dependencies)
    elif is_header:
        print(f"Skipping compile_commands.json update for header: {args.file}")
        print("üí° Use 'projector focus <source_file>' to configure Clangd for this header.")



def find_build_context(hologram_root, start_path):
    """
    Finds the nearest build context (directory with Makefile or compile_commands.json)
    starting from start_path and walking up to hologram_root.
    Returns relative path from hologram_root, or None if no specific context found (root).
    """
    current = os.path.abspath(start_path)
    root = os.path.abspath(hologram_root)
    
    if not current.startswith(root):
        return None
        
    while True:
        # Check markers
        if os.path.exists(os.path.join(current, "Makefile")) or \
           os.path.exists(os.path.join(current, "compile_commands.json")) or \
           os.path.exists(os.path.join(current, ".ddd")):
            if current == root:
                return None # Root is default, no special context needed
            return os.path.relpath(current, root)
            
        parent = os.path.dirname(current)
        if not parent.startswith(root) or parent == current:
            break
        current = parent
        
    return None

def trigger_build(config, context_rel_path=None):
    """
    Triggers the remote build via DDD.
    Manages context switching by restarting the remote daemon if the context has changed.
    """
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]

    # Calculate Target Root
    if context_rel_path:
        remote_root_rel = remote_root.lstrip(os.path.sep)
        if context_rel_path.startswith(remote_root_rel):
             target_root = f"/{context_rel_path}".replace(os.path.sep, "/")
        else:
             target_root = f"{remote_root}/{context_rel_path}".replace(os.path.sep, "/")
    else:
        target_root = remote_root

    # Context State Management
    last_context = config.get('last_context')
    
    # Check if we need to restart
    if last_context != target_root:
        print(f"üîÑ Context Switch Detected: {last_context} -> {target_root}")
        print("   Restarting Remote Daemon...")
        
        # 1. Kill existing session
        try:
             run_command(["ssh"] + ssh_opts + [host, "unset HISTFILE; tmux kill-session -t mission_tower"], capture_stderr=False)
        except Exception:
             pass # Session might not exist, that's fine

        # 2. Launch with new PROJECT_ROOT
        # We need to find the launch_tower script relative to the *original* remote_root
        # because the tools are likely installed there, not in the subdir.
        # Assumption: Tools are in `remote_root/.mission`.
        # Respect remote_mission_root
        remote_mission_root = config.get('remote_mission_root')
        if remote_mission_root:
             mission_root = remote_mission_root
        else:
             mission_root = f"{remote_root}/.mission"
             
        launch_script = f"{mission_root}/tools/bin/launch_tower"
        
        # We start it detached in background via SSH? 
        # launch_tower starts tmux -d, so we just need to run the script.
        # We pass PROJECT_ROOT as env var.
        cmd = f"unset HISTFILE; export PROJECT_ROOT='{target_root}'; {launch_script}"
        
        print(f"   Running: {cmd}")
        try:
             run_command(["ssh"] + ssh_opts + [host, cmd])
        except Exception as e:
             print(f"Error launching tower: {e}")
             # Don't crash, try to trigger anyway?
        
        # Update Config State
        config['last_context'] = target_root
        save_config(config)
        
        # Wait a moment for daemon to stabilize
        time.sleep(1)

    # 3. Trigger
    # The daemon is now running with PROJECT_ROOT = target_root.
    # So it looks for .ddd inside target_root.
    
    # NOTE: target_root might be a subdir.
    # So we touch target_root/.ddd/run/build.request
    
    build_req = f"{target_root}/.ddd/run/build.request"
    
    print(f"Triggering remote build at {build_req}...")
    
    # Ensure run directory exists
    req_dir = os.path.dirname(build_req)
    # Ignore errors (best effort)
    try:
         run_command(["ssh"] + ssh_opts + [host, f"unset HISTFILE; mkdir -p {req_dir}"])
    except Exception:
         pass

    # Reliable Trigger: Remove then Touch (trigger on_created)
    run_command(["ssh"] + ssh_opts + [host, f"unset HISTFILE; rm -f {build_req} && touch {build_req}"])

def find_project_root():
    current = os.path.abspath(os.getcwd())
    while True:
        if os.path.exists(os.path.join(current, CONFIG_FILE)):
            return current
        parent = os.path.dirname(current)
        if parent == current:
            break
        current = parent
    return None

def do_build(args):
    """Explicitly triggers the remote build."""
    config = load_config()
    
    project_root = find_project_root()
    if not project_root:
        print("Error: Could not find project root (.hologram_config).")
        sys.exit(1)
        
    hologram_abs = os.path.join(project_root, HOLOGRAM_DIR)
    
    # Determine Context
    if hasattr(args, 'context_from') and args.context_from:
        # Use provided file's directory
        start_path = os.path.dirname(os.path.abspath(args.context_from))
        print(f"Build Context Derived from: {args.context_from}")
    elif hasattr(args, 'sync') and args.sync:
        # If syncing a file, use that as context derivation too if not specified
        start_path = os.path.dirname(os.path.abspath(args.sync))
        print(f"Build Context Derived from: {args.sync}")
    else:
        # Fallback to CWD
        start_path = os.getcwd()

    # Pre-Build Sync
    if hasattr(args, 'sync') and args.sync:
        print(f"üîÑ Syncing {args.sync} before build...")
        # Create a dummy args object for do_push
        class PushArgs:
            file = args.sync
        try:
            do_push(PushArgs, trigger=False)
        except Exception as e:
            print(f"‚ö†Ô∏è Warning: Sync failed: {e}")
            # Continue to build anyway? Or fail? Let's verify context at least.

    context_path = find_build_context(hologram_abs, start_path)
    
    trigger_build(config, context_path)
    print("‚úÖ Build triggered.")
    
    if hasattr(args, 'wait') and args.wait:
        print("‚è≥ Waiting for build to complete...")
        # Determine log path
        remote_root = config.get('remote_root', '.')
        
        # NOTE: trigger_build MAY have updated last_context in config, but we need to reload it?
        # trigger_build calls save_config.
        config_reloaded = load_config()
        target_root = config_reloaded.get('last_context', remote_root)
        remote_log = f"{target_root}/.ddd/run/build.log"
        
        exit_code = monitor_build(config['host_target'], remote_log, stop_on_finish=True)
        sys.exit(exit_code)

def do_push(args, trigger=False):
    """Pushes a file back to the host."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    local_path = args.file

    # Check for CLI override
    if hasattr(args, 'trigger') and args.trigger:
        trigger = True
    
    project_root = find_project_root()
    if not project_root:
        print("Error: Could not find project root (.hologram_config).")
        sys.exit(1)

    abs_path = os.path.abspath(local_path)
    hologram_abs = os.path.join(project_root, HOLOGRAM_DIR)
    wall_abs = os.path.join(project_root, OUTSIDE_WALL_DIR)
    
    # 1. Check The Wall
    if abs_path.startswith(wall_abs):
        print("üõë VIOLATION: The Wall Breach Detected!")
        print(f"File {local_path} is in the Read-Only 'Outside Wall' zone.")
        print("You cannot push dependencies.")
        sys.exit(1)
        
    # 2. Check Valid Hologram File
    # Use os.path.commonpath to be safe?
    try:
        common = os.path.commonpath([hologram_abs, abs_path])
        if common != hologram_abs:
             print(f"Error: File {local_path} is not in the hologram directory.")
             sys.exit(1)
    except ValueError:
         print(f"Error: Paths on different drives or invalid.")
         sys.exit(1)
        
    # 3. Calculate remote path
    rel_path = os.path.relpath(abs_path, hologram_abs)
    # remote_root comes from config (loaded at start of do_push)
    
    # Handle absolute path mirroring (prevent double nesting)
    remote_root_stripped = remote_root.lstrip(os.path.sep)
    if rel_path.startswith(remote_root_stripped):
         remote_path = f"/{rel_path}".replace(os.path.sep, "/")
    else:
         remote_path = f"{remote_root}/{rel_path}".replace(os.path.sep, "/")
    
    print(f"Pushing {local_path} to {host}:{remote_path}...")
    
    # Ensure remote directory exists
    remote_dir = os.path.dirname(remote_path)
    if remote_dir and remote_dir != ".":
         ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
         # We ignore errors here in case it's a permission thing or exists, rsync will complain if it realy fails
         try:
             run_command(["ssh"] + ssh_opts + [host, f"unset HISTFILE; mkdir -p {remote_dir}"])
         except Exception:
             pass

    rsync_cmd = ["rsync", "-az", "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null", local_path, f"{host}:{remote_path}"]
    run_command(rsync_cmd)
    
    if trigger:
        # Determine Context based on File Location
        context_path = find_build_context(hologram_abs, os.path.dirname(abs_path))
        trigger_build(config, context_path)
        print("Sync & Trigger complete.")
    else:
        print("Sync complete (No Trigger).")

def monitor_build(host, remote_log, stop_on_finish=False, mirror_log=None):
    """
    Monitors the remote build log.
    If stop_on_finish is True, returns 0 on SUCCESS, 1 on FAILURE.
    Includes robust reconnection logic.
    """
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
    
    while True:
        # Pre-Check (only for stop_on_finish)
        # If the build already finished while we were connecting/reconnecting, we might miss the live signal using tail -f.
        # So we check the tail of the file first.
        if stop_on_finish:
             try:
                check_cmd = ["ssh"] + ssh_opts + [host, f"unset HISTFILE; tail -n 50 {remote_log} 2>/dev/null"]
                # Capture output, don't check=True because grep might fail? No, this is just tail.
                res = subprocess.run(check_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
                if res.returncode == 0:
                    for line in res.stdout.splitlines():
                        if "[MISSION COMPLETE]" in line or "BUILD_SUCCESS" in line:
                            print(f"‚úÖ [MISSION COMPLETE] (Detected in log history)", flush=True)
                            return 0
                        if "[MISSION FAILED]" in line or "BUILD_FAILURE" in line:
                            print(f"‚ùå [MISSION FAILED] (Detected in log history)", flush=True)
                            return 1
             except Exception:
                 pass # Ignore pre-check errors, fall through to stream

        # Stream
        cmd = ["ssh"] + ssh_opts + [host, f"unset HISTFILE; tail -F {remote_log} 2>/dev/null"]
        
        try:
            print(f"üì° Tuning into Mission Radio on {host}...", flush=True)
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1)
            
            while True:
                raw_line = process.stdout.readline()
                if not raw_line:
                    # EOF means process died (SSH disconnect?)
                    break
                
                # Mirror
                if mirror_log:
                    try:
                        with open(mirror_log, 'a') as f:
                            f.write(raw_line)
                    except Exception:
                        pass

                line = raw_line.strip()
                if not line:
                    continue
                    
                if line.startswith("[RADIO]"):
                    # Parse Signal
                    payload_str = line[len("[RADIO]"):].strip()
                    try:
                        payload = json.loads(payload_str)
                        event = payload.get("event")
                        msg = payload.get("message")
                        ts = payload.get("timestamp")
                        
                        if event == "BUILD_START":
                            print(f"\nüöÄ [MISSION START] {ts}", flush=True)
                            print(f"   >> {msg}", flush=True)
                        elif event == "BUILD_SUCCESS":
                            print(f"‚úÖ [MISSION COMPLETE] {ts}", flush=True)
                            print(f"   >> {msg}\n", flush=True)
                            if stop_on_finish: return 0
                        elif event == "BUILD_FAILURE":
                            print(f"‚ùå [MISSION FAILED] {ts}", flush=True)
                            print(f"   >> {msg}\n", flush=True)
                            if stop_on_finish: return 1
                        else:
                            print(f"‚ÑπÔ∏è  [RADIO] {event}: {msg}", flush=True)
                            
                    except json.JSONDecodeError:
                        print(f"‚ö†Ô∏è  [RADIO CORRUPT] {line}", flush=True)
                else:
                    print(f"   [log] {line}", flush=True)
            
            # If we get here, the process ended (but wait didn't end).
            # Means SSH dropped.
            if process.poll() is None:
                process.terminate()
                
            print("‚ö†Ô∏è connection lost...", flush=True)
            
        except KeyboardInterrupt:
            print("\nüëã Radio off.")
            if stop_on_finish: 
                sys.exit(130) # Standard interrupt exit
            return
        except Exception as e:
            print(f"Error listening: {e}")
            
        if stop_on_finish:
            print("üîÑ Reconnecting in 3s...", flush=True)
            time.sleep(3)
        else:
            return # If not waiting for finish (interactive listen), just exit on break? 
                   # Actually, legacy behavior was 'tail -F' which handles some retries, 
                   # but SSH wrapper breaks that. 
                   # For 'listen', user might prefer auto-reconnect too? 
                   # Let's keep it robust for both.
            print("üîÑ Reconnecting in 3s...", flush=True)
            time.sleep(3)


def do_listen(args):
    """Listens to the Mission Radio (remote build logs)."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    target_root = config.get('last_context', remote_root)
    remote_log = f"{target_root}/.ddd/run/build.log"
    
    mirror_log = args.mirror_log if hasattr(args, 'mirror_log') else None
    
    monitor_build(host, remote_log, stop_on_finish=False, mirror_log=mirror_log)




def do_live(args):
    """Reflex + Impulse + Synthesis: Live Mode"""
    print("üß† The Synapse is active. (Live Mode)")
    
    # 1. Start Synthesis (The Radio) in a background thread
    print("üëÇ Connecting to The Radio...")

    # Configure Log Mirroring to Hologram
    # We mirror the remote build log to local hologram/.ddd/run/build.log
    # This allows 'Local Smith' to see the logs as if they were local files.
    mirror_path = os.path.join(HOLOGRAM_DIR, ".ddd", "run", "build.log")
    os.makedirs(os.path.dirname(mirror_path), exist_ok=True)
    args.mirror_log = mirror_path
    
    print(f"ü™û Mirroring logs to {mirror_path}")

    radio_thread = threading.Thread(target=do_listen, args=(args,), daemon=True)
    radio_thread.start()
    
    # 2. Start Reflex (Watcher) & Impulse (Auto-Push)
    print("üëÅÔ∏è  Watching hologram for changes...")
    
    # Simple timestamp-based polling
    poll_interval = 1.0 # seconds
    debounce_delay = 0.5
    
    last_mtimes = {}
    pending_changes = set()
    
    # Initial scan to populate mtimes
    if os.path.exists(HOLOGRAM_DIR):
        for root, dirs, files in os.walk(HOLOGRAM_DIR):
            for f in files:
                path = os.path.join(root, f)
                try:
                    last_mtimes[path] = os.path.getmtime(path)
                except OSError:
                    pass
    else:
        print(f"Warning: {HOLOGRAM_DIR} does not exist. Please run 'projector init' first.")
        # We continue anyway, as it might be created later or user might want to init in another terminal
                
    try:
        while True:
            time.sleep(poll_interval)
            
            # Scan for changes
            current_changes = set()
            if os.path.exists(HOLOGRAM_DIR):
                for root, dirs, files in os.walk(HOLOGRAM_DIR):
                    for f in files:
                        path = os.path.join(root, f)
                        try:
                            mtime = os.path.getmtime(path)
                            if path not in last_mtimes:
                                last_mtimes[path] = mtime
                                current_changes.add(path)
                            elif mtime > last_mtimes[path]:
                                last_mtimes[path] = mtime
                                current_changes.add(path)
                        except OSError:
                            pass
            
            if current_changes:
                # Add to pending and wait for debounce
                pending_changes.update(current_changes)
                print(f"‚ö° Reflex: Detected {len(current_changes)} changes. Debouncing...")
                time.sleep(debounce_delay)
                
                # Impulse: Push all pending changes
                files_to_push = list(pending_changes)
                pending_changes.clear()
                
                # Context logic for live mode?
                # The first file determines context? 
                # Or we sync all, then pick one for context?
                # Simple: Use the first one.
                first_file = None
                
                for f_path in files_to_push:
                    if os.path.exists(f_path): # Check again
                        if not first_file: first_file = f_path
                        print(f"üåä Impulse: Pushing {f_path}...")
                        # Create a dummy args object
                        class PushArgs:
                            file = f_path
                        
                        try:
                            # We don't trigger per file anymore
                            do_push(PushArgs(), trigger=False)
                        except SystemExit:
                             # do_push calls sys.exit(1) on failure, we must catch it
                            print(f"‚ö†Ô∏è Push failed for {f_path}")
                        except Exception as e:
                            print(f"‚ö†Ô∏è Error pushing {f_path}: {e}")
                            
                # Trigger ONCE after batch (if auto-build is enabled)
                if args.auto_build and first_file:
                    print("Triggering remote build for batch...")
                    # Determine context from first file
                    hologram_abs = os.path.abspath(HOLOGRAM_DIR)
                    context_path = find_build_context(hologram_abs, os.path.dirname(first_file))
                    trigger_build(load_config(), context_path)
                    print("‚ú® Synced & Triggered.")
                else:
                    print("‚ú® Synced (Use 'projector build' or run with --auto-build to trigger).")

    except KeyboardInterrupt:
        print("\nüîå Disconnecting Synapse.")
        sys.exit(0)



def retract_file(abs_path, config, project_root):
    """
    Retracts a single file: removes from hologram, restores to outside_wall if possible.
    Returns True if successful/processed, False on error.
    """
    input_path = os.path.relpath(abs_path, os.getcwd()) # For display
    hologram_abs = os.path.join(project_root, HOLOGRAM_DIR)
    
    # 1. Validate Path (Already done if walking, but good for safety)
    try:
        common = os.path.commonpath([hologram_abs, abs_path])
        if common != hologram_abs:
             print(f"Error: File {input_path} is not in the hologram directory.")
             return False
    except ValueError:
         print(f"Error: Paths on different drives or invalid.")
         return False
         
    # 2. Remove File
    if os.path.exists(abs_path):
        os.remove(abs_path)
        print(f"üóëÔ∏è  Retracted {input_path} from hologram.")
    else:
        print(f"Warning: File {input_path} does not exist locally.")
        
    # 2b. Restore to Outside Wall (if remote exists)
    try:
        rel_path = os.path.relpath(abs_path, hologram_abs)
        host = config['host_target']
        remote_root = config.get('remote_root', '.')
        
        # Calculate Remote Path
        remote_root_stripped = remote_root.lstrip(os.path.sep)
        if rel_path.startswith(remote_root_stripped):
             remote_path = f"/{rel_path}".replace(os.path.sep, "/")
        else:
             remote_path = f"{remote_root}/{rel_path}".replace(os.path.sep, "/")

        # Check Remote Existence
        ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
        check_cmd = ["ssh"] + ssh_opts + [host, f"unset HISTFILE; test -f {remote_path}"]
        subprocess.check_call(check_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        # Restore
        wall_dest = os.path.join(project_root, OUTSIDE_WALL_DIR, rel_path)
        # Check if we should restore? 
        # Logic: If it exists remotely, we assume it should be in outside_wall as 'base'
        
        os.makedirs(os.path.dirname(wall_dest), exist_ok=True)
        
        rsync_cmd = ["rsync", "-az", "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null", f"{host}:{remote_path}", wall_dest]
        run_command(rsync_cmd)
             
        # Enforce Read-Only
        os.chmod(wall_dest, 0o444)
        print(f"üß± Restored {os.path.basename(wall_dest)} to Outside Wall.")
        
    except subprocess.CalledProcessError:
        # Remote file doesn't exist, so nothing to restore
        pass
    except Exception as e:
        print(f"Warning: Failed to restore to outside_wall: {e}")
        
    return True

def do_retract(args):
    """Retracts a file from the hologram (stops projecting it)."""
    config = load_config() # ensure we are in a hologram
    project_root = find_project_root()
    hologram_abs = os.path.join(project_root, HOLOGRAM_DIR)
    cwd = os.getcwd()
    
    files_to_retract = []
    
    if args.all:
        print("üí• Retracting ALL files from Hologram...")
        if os.path.exists(hologram_abs):
            for root, dirs, files in os.walk(hologram_abs):
                for f in files:
                    full_path = os.path.join(root, f)
                    # Skip config or internal files?
                    if f == "compile_commands.json" or f == ".hologram_config":
                        continue
                    files_to_retract.append(full_path)
    else:
        if not args.file:
            print("Error: Must specify a file or --all")
            sys.exit(1)
            
        input_path = args.file
        abs_path = os.path.abspath(input_path)
        
        # Smart Resolution: If path is not in hologram, try to find it inside.
        if not abs_path.startswith(hologram_abs):
            # Try joining with hologram
            # If input_path is relative, it's relative to CWD.
            # We want to treat it as relative to PROJECT ROOT? Or just append to hologram?
            # 1. Try relative to CWD mapped to Hologram
            # e.g. CWD=/chaos, input=asic/zsdk/foo.c -> /chaos/hologram/asic/zsdk/foo.c
            
            # rel to project root
            try:
                rel_to_root = os.path.relpath(abs_path, project_root)
                candidate = os.path.join(hologram_abs, rel_to_root)
                if os.path.exists(candidate):
                    abs_path = candidate
                else:
                    # check if we are in outside_wall? 
                    pass
                    # e.g. input=src/main.c -> hologram/src/main.c
                    # This is covered above if CWD=project_root.
                    # What if user is in a subdir?
                    pass
            except ValueError:
                pass
        
        files_to_retract.append(abs_path)
        
    # Process
    if not files_to_retract:
        print("Nothing to retract.")
        return

    for f_path in files_to_retract:
        retract_file(f_path, config, project_root)
        
    # 3. Clean up compile_commands.json
    db_path = os.path.join(hologram_abs, "compile_commands.json")
    if os.path.exists(db_path):
        try:
            with open(db_path, 'r') as f:
                db = json.load(f)
            
            # Filter out any retracted files
            # Note: files_to_retract contains absolute paths
            retracted_set = set(files_to_retract)
            new_db = [e for e in db if os.path.abspath(e.get("file")) not in retracted_set]
            
            if len(db) != len(new_db):
                with open(db_path, 'w') as f:
                    json.dump(new_db, f, indent=2)
                print(f"cleaned compile_commands.json entries.")
        except Exception as e:
            print(f"Warning: Failed to update compile_commands.json: {e}")
            
    # Cleanup empty directories in hologram? (Optional but nice)
    if args.all:
         # simple walk up and rmdir if empty
         for root, dirs, files in os.walk(hologram_abs, topdown=False):
             for name in dirs:
                 d_path = os.path.join(root, name)
                 try:
                     # os.rmdir only removes empty dirs
                     os.rmdir(d_path)
                 except OSError:
                     pass

def do_grep(args):
    """Executes remote ripgrep and maps paths to local hologram."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    
    pattern = args.pattern
    search_path = args.path
    
    # Resolve Remote Search Path
    if search_path:
        abs_search = os.path.abspath(search_path)
        project_root = find_project_root()
        hologram_abs = os.path.join(project_root, HOLOGRAM_DIR)
        
        # Check if inside hologram
        if abs_search.startswith(hologram_abs):
            rel = os.path.relpath(abs_search, hologram_abs)
            remote_search_path = os.path.join(remote_root, rel)
        else:
            # Assume relative to remote root or explicit remote path?
            # Let's treat it as relative to CWD, which maps to remote root if not in hologram?
            # Or just pass thorough if it looks like a remote path (starts with /)?
            if search_path.startswith("/"):
                remote_search_path = search_path
            else:
                remote_search_path = os.path.join(remote_root, search_path)
    else:
        remote_search_path = remote_root

    # Construct Command
    # We use -n (line number), -H (with filename), --no-heading (for parsing)
    # prepend unset HISTFILE to avoid pollution
    cmd_str = f"unset HISTFILE; rg --line-number --with-filename --no-heading --color=always {pattern} {remote_search_path}"
    
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
    cmd = ["ssh"] + ssh_opts + [host, cmd_str]
    
    try:
        # Stream output line by line
        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1)
        
        hologram_cwd = os.path.join(find_project_root(), HOLOGRAM_DIR)
        
        while True:
            line = process.stdout.readline()
            if not line:
                break
                
            # Rewrite Path
            # Output format: <path>:<line>: <content> (with color codes potentially)
            # We need to be careful with color codes. `rg` puts color codes around filenames too.
            # But we can try to find the first colon?
            
            # Simple heuristic: Split by first colon
            # Note: Path might contain colons? 
            # rg default format usually safe.
            
            # To reliably rewrite, strict ANSI stripping might be needed, but let's try a simpler approach first.
            # If we detect remote_root, replace with hologram_cwd
            
            # Remove remote_root from the line?
            # Or replace `remote_root/` with `hologram/`?
            
            # We need to display relative to CWD or Absolute? VSCode likes Absolute or relative to workspace.
            # Let's use Absolute Hologram paths so they are clickable.
            
            # We just do string replacement on the line. 
            # It's a bit hacky but fast.
            # But remote_root might be short (e.g. /app).
            
            decoded_line = line
            
            # Strip ANSI for matching? No, we print with color.
            # Just replace valid path substrings.
            
            # Strategy:
            # 1. Identify valid path prefix in the line.
            # 2. Replace it.
            
            # Since we know `remote_root`, we can replace `remote_root` with `hologram_cwd`.
            # This works if rg prints absolute paths. 
            # Does rg print absolute paths? 
            # If we gave it an absolute path, yes.
            # We constructed `remote_search_path` as absolute (mostly).
            
            # If `remote_root` is `/repos/project0`, and `hologram` is `/Users/me/chaos/hologram`
            # We replace `/repos/project0` -> `/Users/me/chaos/hologram`
            
            if remote_root in decoded_line:
                # Blind replacement might be dangerous if content matches, but rg puts path at start.
                # Only replace at start?
                # Color codes might precede it.
                
                # Let's just do global replace for now, risk is low for distinct paths.
                new_line = decoded_line.replace(remote_root, hologram_cwd, 1) # Count=1 to be safer
                print(new_line, end='')
            else:
                print(decoded_line, end='')

        # Check return code
        process.wait()
        if process.returncode != 0 and process.returncode != 1: # 1 is no matches, which is fine
             # Print stderr if any error occurred
             err = process.stderr.read()
             if "command not found" in err:
                 print("Error: 'rg' (ripgrep) not found on remote host.")
             elif err:
                 print(err, end='')
                 
    except Exception as e:
        print(f"Error executing grep: {e}")

def do_log(args):
    """Fetches the latest build log from the remote host."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    
    # Prefer last_context (where the daemon is actually running)
    target_root = config.get('last_context', remote_root)
    remote_log = f"{target_root}/.ddd/run/build.log"
    
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
    
    # Default to cat, but support --lines
    if args.lines:
        cmd_str = f"unset HISTFILE; tail -n {args.lines} {remote_log} 2>/dev/null"
        cmd = ["ssh"] + ssh_opts + [host, cmd_str]
    else:
        cmd_str = f"unset HISTFILE; cat {remote_log} 2>/dev/null"
        cmd = ["ssh"] + ssh_opts + [host, cmd_str]
        
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        if result.returncode != 0:
            print(f"Error: Could not retrieve log from {host}:{remote_log}")
            sys.exit(1)
            
        print(result.stdout, end='') 
        
    except Exception as e:
        print(f"Error fetching log: {e}")
        sys.exit(1)

def do_repair_headers(args):
    """Syncs system headers from the remote host."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    
    print("üöë  Repairing System Headers...")
    
    # 1. Find or Deploy sys_headers.py
    # We assume it's in ~/.mission/tools/lib/sys_headers.py (deployed by init/pull)
    # But let's verify path relative to remote_root if possible or fallback
    
    # Force use of remote_root (or configured mission root) for tools
    # consistently with our manual deployment in previous steps
    remote_mission_root = config.get('remote_mission_root')
    if remote_mission_root:
         sys_headers_bin = f"{remote_mission_root}/tools/lib/sys_headers.py"
    else:
         sys_headers_bin = f"{remote_root}/.mission/tools/lib/sys_headers.py"
         
    cmd = f"chmod +x {sys_headers_bin} && {sys_headers_bin}"
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
    
    try:
        print("   Querying remote compiler for default includes...")
        # Prevent history pollution
        full_cmd = ["ssh"] + ssh_opts + [host, f"unset HISTFILE; {cmd}"]
        
        result = subprocess.run(full_cmd, 
                                stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        if result.returncode != 0:
            print(f"Error querying headers: {result.stderr}")
            # Try fallback to hardcoded if script missing?
            sys.exit(1)
            
        includes = [line.strip() for line in result.stdout.splitlines() if line.strip()]
        
        if not includes:
            print("Warning: No system includes found. Check if proper compiler is installed on remote.")
            print("         (e.g. gcc/g++ or clang)")
            return

        print(f"   Found {len(includes)} system include paths.")
        
        # 2. Sync to Outside Wall
        # Loop through includes and sync each recursively.
        # --files-from with directories can be tricky regarding recursion with older rsync.
        
        print(f"   Syncing {len(includes)} paths (recursive)...")
        
        for inc in includes:
             # Ensure we don't sync obvious root paths or massive dirs accidentally? 
             # (Compiler gives specific include dirs, usually safe)
             print(f"     - {inc}")
             rsync_cmd = [
                "rsync", "-azR", # -R preserves full path (e.g. /usr/include -> outside_wall/usr/include)
                "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null",
                f"{host}:{inc}", 
                OUTSIDE_WALL_DIR
             ]
             try:
                 subprocess.run(rsync_cmd, check=True, stderr=subprocess.PIPE)
             except subprocess.CalledProcessError as e:
                 print(f"       Warning: Failed to sync {inc}: {e}")
                 print(f"                (Is it a valid directory on remote?)")
                 # Continue to next
        
        # 3. Save to Config
        # We need to persist these so update_local_compile_db can use them
        config["system_includes"] = includes
        save_config(config)
        
        # 4. Update Compile DB
        # We call update_local_compile_db with an empty context just to trigger the rewrite with new flags
        print("   Updating compilation database...")
        update_local_compile_db({})
        
        print("‚úÖ  System headers repaired and synced.")
        
    except Exception as e:
        print(f"Repair failed: {e}")
        sys.exit(1)

def do_context(args):
    """
    Displays the compilation context for a file in a structured format for AI agents.
    Read from local compile_commands.json.
    """
    project_root = find_project_root()
    if not project_root:
        print("Error: Hologram not initialized.")
        sys.exit(1)
        
    hologram_dir = os.path.join(project_root, HOLOGRAM_DIR)
    db_path = os.path.join(hologram_dir, "compile_commands.json")
    
    if not os.path.exists(db_path):
        print(f"Error: {db_path} not found. Run 'projector pull' first.")
        sys.exit(1)
        
    # Resolve Target File
    target_path = os.path.abspath(args.file) # Local absolute
    
    # Load DB
    try:
        with open(db_path, 'r') as f:
            db = json.load(f)
    except Exception as e:
        print(f"Error parsing compile_commands.json: {e}")
        sys.exit(1)
        
    # Find Entry
    # DB entries usually have "file" as absolute path (rewritten by projector)
    entry = next((e for e in db if e.get("file") == target_path), None)
    
    if not entry:
        # Try resolving via relative path matching?
        # Sometimes DB has symlinks resolved or vice versa.
        # But projector rewrites it to match hologram structure. 
        # If user passes relative path, abspath should match.
        print(f"Error: No compilation context found for {args.file}")
        print("Tip: Run 'projector pull' to sync context.")
        sys.exit(1)
        
    # Parse Command
    import shlex
    cmd_args = []
    if "arguments" in entry:
        cmd_args = entry["arguments"]
    elif "command" in entry:
        cmd_args = shlex.split(entry["command"])
        
    macros = []
    includes = []
    standard = None
    
    i = 0
    while i < len(cmd_args):
        arg = cmd_args[i]
        
        # Macros
        if arg.startswith("-D"):
            macros.append(arg[2:])
            
        # Standard
        elif arg.startswith("-std="):
            standard = arg[5:]
            
        # Includes
        elif arg.startswith("-I"):
            val = arg[2:]
            if not val and i + 1 < len(cmd_args):
                val = cmd_args[i+1]
            if val: includes.append(val)
        elif arg == "-isystem":
            if i + 1 < len(cmd_args):
                includes.append(cmd_args[i+1])
        
        i += 1
        
    # STRUCTURED OUTPUT (YAML-like for AI)
    print(f"File: {os.path.relpath(target_path, project_root)}")
    if standard:
        print(f"Standard: {standard}")
    
    print("Macros:")
    if macros:
        for m in sorted(macros):
            print(f"  - {m}")
    else:
        print("  (None)")
        
    print("Includes:")
    if includes:
        for inc in includes:
            # Show paths relative to project root if internal
            if inc.startswith(project_root):
                rel = os.path.relpath(inc, project_root)
                print(f"  - {rel}")
            else:
                print(f"  - {inc}")
    else:
        print("  (None)")

def do_focus(args):
    """
    Generates a dynamic .clangd configuration derived from a source file's compilation flags.
    This allows headers to inherit the correct context without polluting compile_commands.json.
    """
    project_root = find_project_root()
    if not project_root:
        print("Error: Hologram not initialized.")
        sys.exit(1)
        
    hologram_dir = os.path.join(project_root, HOLOGRAM_DIR)
    db_path = os.path.join(hologram_dir, "compile_commands.json")
    
    if not os.path.exists(db_path):
        print(f"Error: {db_path} not found. Run 'projector pull' first.")
        sys.exit(1)
        
    # Resolve Target File
    # User provides local path (relative or absolute)
    target_path = os.path.abspath(args.file)
    
    # Load DB
    try:
        with open(db_path, 'r') as f:
            db = json.load(f)
    except Exception as e:
        print(f"Error parsing compile_commands.json: {e}")
        sys.exit(1)
        
    # Find Entry
    entry = next((e for e in db if e.get("file") == target_path), None)
    
    if not entry:
        print(f"Error: No compilation context found for {args.file}")
        print("Make sure this source file has been pulled via 'projector pull'.")
        sys.exit(1)
        
    print(f"Found context for {args.file}")
    
    # Extract Flags
    import shlex
    cmd_args = []
    if "arguments" in entry:
        cmd_args = entry["arguments"]
    elif "command" in entry:
        cmd_args = shlex.split(entry["command"])
        
    # We want: -D, -U, -I, -isystem, -std, -f*, -m*, -W*
    # We essentially want everything except the compiler binary, -c, -o, and the input file.
    
    compile_flags = []
    
    i = 0
    while i < len(cmd_args):
        arg = cmd_args[i]
        
        # Skip compiler binary (heuristic: first arg if not flag?)
        # But cmd_args might start with flags if "arguments" is used.
        # "arguments": ["/usr/bin/gcc", "-c", ...] usually.
        if i == 0 and not arg.startswith("-"):
             i += 1
             continue
             
        # Skip output
        if arg == "-o":
            i += 2 # skip val
            continue
            
        # Skip input file (exact match)
        # Note: target_path is absolute local, but args might have relative or mapped path?
        # Safer to just skip anything that looks like a source file if we are unsure,
        # but let's just skip -c and -o. Clangd is smart enough to ignore input file in flags usually?
        # Actually .clangd Add flags are added to the command. We don't want input file there.
        
        # Skip -c
        if arg == "-c":
            i += 1
            continue
            
        # Keep everything else?
        # We assume cmd_args are valid flags.
        
        # Handle separated flags (like -I val) to merge them for .clangd?
        # .clangd supports list of strings.
        # "Add": ["-I", "/path"] is valid.
        
        compile_flags.append(arg)
        i += 1
        
    # Filter out input file if it ended up in flags
    # (Checking if arg is the file path)
    compile_flags = [f for f in compile_flags if not f.endswith(".c") and not f.endswith(".cpp") and not f.endswith(".cc")]
    
    # Generate .clangd content
    # YAML format
    
    clangd_content = "CompileFlags:\n  Add:\n"
    for flag in compile_flags:
        # Quote flags to avoid yaml parsing issues
        # Escape quotes inside?
        safe_flag = flag.replace('"', '\\"')
        clangd_content += f'    - "{safe_flag}"\n'
        
    clangd_path = os.path.join(hologram_dir, ".clangd")
    
    try:
        with open(clangd_path, 'w') as f:
            f.write(clangd_content)
        print(f"‚úÖ Generated .clangd configuration at {clangd_path}")
        print(f"   (Derived {len(compile_flags)} flags from {os.path.basename(target_path)})")
    except Exception as e:
        print(f"Error writing .clangd: {e}")
        sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description="Projector Agent: Manage Remote Brain Hologram")
    subparsers = parser.add_subparsers(dest="command", required=True)
    
    # Init
    p_init = subparsers.add_parser("init", help="Initialize hologram")
    p_init.add_argument("host_target", help="SSH target (user@host)")
    p_init.add_argument("--remote-root", help="Absolute path to remote repository root", default=".")
    p_init.set_defaults(func=do_init)
    
    # Pull
    p_pull = subparsers.add_parser("pull", help="Pull file from host")
    p_pull.add_argument("file", help="Remote absolute file path")
    p_pull.add_argument("--flags", help="Flags to filter compilation context (e.g. \"-DTEST\")")
    p_pull.set_defaults(func=do_pull)
    
    # Push
    p_push = subparsers.add_parser("push", help="Push file to host")
    p_push.add_argument("file", help="Local file path")
    p_push.add_argument("--trigger", action="store_true", help="Trigger remote build after push")
    p_push.set_defaults(func=do_push)
    
    # Retract
    p_retract = subparsers.add_parser("retract", help="Stop projecting a file (remove locally)")
    p_retract.add_argument("file", nargs="?", help="Local file path")
    p_retract.add_argument("--all", action="store_true", help="Retract ALL files from hologram")
    p_retract.set_defaults(func=do_retract)

    # Grep
    p_grep = subparsers.add_parser("grep", help="Run ripgrep on remote and map to hologram")
    p_grep.add_argument("pattern", help="Search pattern")
    p_grep.add_argument("path", nargs="?", help="Search path (optional)")
    p_grep.set_defaults(func=do_grep)
    
    # Listen
    p_listen = subparsers.add_parser("listen", help="Listen to remote broadcast")
    p_listen.add_argument("--mirror-log", help="Path to mirror raw log file locally")
    p_listen.set_defaults(func=do_listen)
    
    # Log (Atomic)
    p_log = subparsers.add_parser("log", help="Fetch remote build log (One-shot)")
    p_log.add_argument("-n", "--lines", type=int, help="Number of lines to tail")
    p_log.set_defaults(func=do_log)
    
    # Build
    p_build = subparsers.add_parser("build", help="Trigger remote build manually")
    p_build.add_argument("--context-from", help="Derive build context from this file path")
    p_build.add_argument("--sync", help="Synchronize specific file before building")
    p_build.add_argument("--wait", action="store_true", help="Wait for build completion and stream logs")
    p_build.set_defaults(func=do_build)
    
    # Live
    p_live = subparsers.add_parser("live", help="Live mode (Watch + Push + Listen)")
    p_live.add_argument("--auto-build", action="store_true", help="Enable automatic build triggering on file changes")
    p_live.set_defaults(func=do_live)

    # Focus (Clangd)
    p_focus = subparsers.add_parser("focus", help="Generate .clangd config from a source file")
    p_focus.add_argument("file", help="Source file (C/C++) to derive flags from")
    p_focus.set_defaults(func=do_focus)
    
    # Context (AI)
    p_context = subparsers.add_parser("context", help="Show AI-friendly compilation context")
    p_context.add_argument("file", help="Local file path")
    p_context.set_defaults(func=do_context)

    # Repair Headers
    p_repair = subparsers.add_parser("repair-headers", help="Sync missing system headers")
    p_repair.set_defaults(func=do_repair_headers)
    
    # Pre-process sys.argv to handle --flags "-D..." issue
    # argparse confuses values starting with - as new flags.
    # We convert ['--flags', '-D...'] to ['--flags=-D...']
    argv_clean = []
    i = 0
    raw_args = sys.argv[1:]
    while i < len(raw_args):
        arg = raw_args[i]
        if arg == "--flags" and i + 1 < len(raw_args):
            val = raw_args[i+1]
            if val.startswith("-"):
                argv_clean.append(f"--flags={val}")
                i += 2
                continue
        argv_clean.append(arg)
        i += 1

    args = parser.parse_args(argv_clean)
    args.func(args)

if __name__ == "__main__":
    main()
