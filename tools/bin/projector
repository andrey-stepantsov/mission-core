#!/usr/bin/env python3
import argparse
import os
import sys
import subprocess
import json
import shutil
import time
import threading

HOLOGRAM_DIR = "hologram"
OUTSIDE_WALL_DIR = "outside_wall"
CONFIG_FILE = ".hologram_config"

def run_command(cmd, shell=False, capture_stderr=True):
    """Runs a shell command and returns stdout."""
    try:
        stderr_dest = subprocess.PIPE if capture_stderr else sys.stderr
        result = subprocess.run(cmd, shell=shell, check=True, stdout=subprocess.PIPE, stderr=stderr_dest, text=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        # Check if stderr is just noise (warnings)
        err_msg = e.stderr if e.stderr else ""
        lines = err_msg.splitlines()
        real_errors = [l for l in lines if not (l.startswith("Warning:") or "setlocale" in l)]
        
        if real_errors:
            print(f"Error running command: {cmd}")
            print(f"Stderr: {err_msg}")
        elif not capture_stderr:
             # If we weren't capturing, typically means interactive or we don't care about output unless failed
            print(f"Command failed with exit code {e.returncode}: {cmd}")
            
        raise e  # Re-raise so caller handles flow

def load_config():
    # print("DEBUG: Entering load_config")
    current = os.path.abspath(os.getcwd())
    while True:
        candidate = os.path.join(current, CONFIG_FILE)
        if os.path.exists(candidate):
            with open(candidate, 'r') as f:
                return json.load(f)
        
        parent = os.path.dirname(current)
        if parent == current:
            break
        current = parent
        
    print("Error: Hologram not initialized (Config not found). Run 'projector init <host>' first.")
    sys.exit(1)

def save_config(config):
    # Always save to CWD or explicit root?
    # For now, save to CWD as that's usually init root
    with open(CONFIG_FILE, 'w') as f:
        json.dump(config, f, indent=4)


def do_init(args):
    """Initializes the hologram environment."""
    host_target = args.host_target
    
    # Support user@host:path syntax
    if ":" in host_target:
        parts = host_target.split(":", 1)
        host_target = parts[0]
        # Only override remote_root if not explicitly provided
        if not args.remote_root or args.remote_root == ".":
            remote_root = parts[1]
        else:
            remote_root = args.remote_root
    else:
        remote_root = args.remote_root
        
    remote_root = remote_root.rstrip("/") if remote_root else "."
    
    print(f"Initializing Hologram for host: {host_target} (Root: {remote_root})")
    
    os.makedirs(HOLOGRAM_DIR, exist_ok=True)
    os.makedirs(OUTSIDE_WALL_DIR, exist_ok=True)
    
    config = {
        "host_target": host_target,
        "remote_root": remote_root
    }
    save_config(config)
    print("Hologram initialized.")
    
    # 4. Launch The Tower (Observability)
    print("Launching The Tower (Remote Watcher)...")
    
    # Use explicit remote root to find launch_tower
    tower_script = f"{remote_root}/.mission/tools/bin/launch_tower"
    
    # Fallback logic if root is '.', try typical locations
    if remote_root == ".":
         tower_cmd = (
            "if [ -f .mission/tools/bin/launch_tower ]; then ./.mission/tools/bin/launch_tower; "
            "elif [ -f /mission/tools/bin/launch_tower ]; then /mission/tools/bin/launch_tower; "
            "else echo 'Tower script not found at ./.mission or /mission'; fi"
        )
    else:
        tower_cmd = f"if [ -f {tower_script} ]; then {tower_script}; else echo 'Tower script not found at {tower_script}'; fi"
    
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]

    run_command(["ssh"] + ssh_opts + [host_target, tower_cmd], capture_stderr=False)

    # 5. Deploy VSCode Configuration
    deploy_vscode_config(remote_root)

def deploy_vscode_config(remote_root):
    """Deploys VSCode configuration templates if they exist."""
    print("Deploying VSCode configuration...")
    
    # Try to find templates in local .mission first (if sideloaded)
    # The projector script is in .mission/tools/bin/projector
    # So templates should be in .mission/templates/vscode
    
    script_dir = os.path.dirname(os.path.realpath(__file__))
    # script_dir = .../.mission/tools/bin
    mission_root = os.path.dirname(os.path.dirname(os.path.dirname(script_dir)))
    # mission_root = .../.mission (if running from source) or just use relative if trustworthy
    
    # More robust finding strategy:
    # 1. Check relative to script location
    template_src = os.path.join(script_dir, "../../templates/vscode")
    
    if not os.path.exists(template_src):
        # 2. Check CWD/.mission (setup scenario)
        template_src = os.path.join(os.getcwd(), ".mission", "templates", "vscode")
        
    if os.path.exists(template_src):
        target_vscode = os.path.join(os.getcwd(), ".vscode")
        os.makedirs(target_vscode, exist_ok=True)
        
        for item in os.listdir(template_src):
            s = os.path.join(template_src, item)
            d = os.path.join(target_vscode, item)
            if os.path.isfile(s):
                if not os.path.exists(d):
                    shutil.copy2(s, d)
                    print(f"  Created {item}")
                else:
                    print(f"  Skipped {item} (already exists)")
    else:
        print("  Warning: VSCode templates not found.")



def update_local_compile_db(context, dependencies=None):
    """Updates the unified local compile_commands.json with rewritten paths."""
    if not context:
        return

    config = load_config()
    remote_root = config.get('remote_root', '.')
    
    # Paths (Absolute Local)
    # We use os.getcwd() because hologram/outside_wall are in CWD where projector runs
    cwd = os.getcwd()
    hologram_abs = os.path.join(cwd, HOLOGRAM_DIR)
    outside_wall_abs = os.path.join(cwd, OUTSIDE_WALL_DIR)
    
    # 1. Rewrite Directory
    # context['directory'] is the remote build directory.
    # We map this to hologram structure.
    remote_dir = context.get('directory', '')
    if remote_dir.startswith(remote_root):
        rel_dir = os.path.relpath(remote_dir, remote_root)
        local_dir = os.path.join(hologram_abs, rel_dir)
    else:
        # If build dir is outside remote root (weird), fall back to hologram root
        local_dir = hologram_abs
        
    # 2. Rewrite File
    # context['file'] is remote absolute path
    remote_file = context.get('file', '')
    if remote_file.startswith(remote_root):
        rel_file = os.path.relpath(remote_file, remote_root)
        local_file = os.path.join(hologram_abs, rel_file)
    else:
        # If file is outside (e.g. system header?), we can't really edit it.
        # But auto_ghost usually targets files in repo.
        local_file = remote_file
        
    # 3. Rewrite Arguments
    # Rewrite -I /abs/path -> -I .../outside_wall/abs/path
    args = context.get('arguments', [])
    new_args = []
    
    i = 0
    while i < len(args):
        arg = args[i]
        
        # Handle -I /path
        if arg.startswith("-I") or arg.startswith("-L") or arg == "-isystem":
            # Check if it's a flag + value or separated
            flag = arg
            value = None
            consumed_next = False
            
            if arg == "-isystem":
                 if i + 1 < len(args):
                    value = args[i+1]
                    consumed_next = True
            elif len(arg) > 2:
                # -I/path
                flag = arg[:2]
                value = arg[2:]
            else:
                # -I /path
                 if i + 1 < len(args):
                    value = args[i+1]
                    consumed_next = True
            
            if value and value.startswith("/"):
                # Rewrite to outside_wall
                # /opt/foo -> .../outside_wall/opt/foo
                mapped_path = os.path.join(outside_wall_abs, value.lstrip("/"))
                
                # Check if we should enforce mapping or keep original?
                # Ideally, if we synced it, it exists.
                # If we didn't sync it (e.g. standard lib), maybe we shouldn't rewrite?
                # But typically we want to point to our 'sysroot'.
                # Let's map it.
                
                if consumed_next:
                    new_args.append(flag)
                    new_args.append(mapped_path)
                    i += 2
                else:
                    new_args.append(f"{flag}{mapped_path}")
                    i += 1
                continue
                
        new_args.append(arg)
        i += 1
        
    # 3b. Inject Dependency Includes
    if dependencies:
        include_dirs = set()
        system_dirs = set()
        
        for dep in dependencies:
            if not dep.startswith("/"):
                continue
                
            # Map to outside_wall
            rel_dep = dep.lstrip("/")
            local_dep = os.path.join(outside_wall_abs, rel_dep)
            local_dep_dir = os.path.dirname(local_dep)
            
            # Heuristic: /usr, /opt, /lib are likely system
            if dep.startswith("/usr") or dep.startswith("/opt") or dep.startswith("/lib"):
                system_dirs.add(local_dep_dir)
            else:
                include_dirs.add(local_dep_dir)
                
        # Append new flags
        for d in sorted(list(include_dirs)):
            new_args.append(f"-I{d}")
            
        for d in sorted(list(system_dirs)):
            new_args.append(f"-isystem{d}")
        
    entry = {
        "directory": local_dir,
        "file": local_file,
        "arguments": new_args
    }
    
    # 4. Upsert into compile_commands.json
    db_path = os.path.join(hologram_abs, "compile_commands.json")
    db = []
    if os.path.exists(db_path):
        try:
            with open(db_path, 'r') as f:
                db = json.load(f)
        except:
             pass
             
    # Remove existing entry for this file
    db = [e for e in db if e.get("file") != local_file]
    db.append(entry)
    
    with open(db_path, 'w') as f:
        json.dump(db, f, indent=2)
        
    print(f"Updated compile_commands.json for {os.path.basename(local_file)}")

    print(f"Updated compile_commands.json for {os.path.basename(local_file)}")

def do_pull(args):
    """Pulls a file from the host."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    
    input_path = args.file
    
    # Resolve Remote Path
    if input_path.startswith("/"):
        remote_path = input_path
        # For absolute paths, we store them as full structure
        rel_path = input_path.lstrip("/")
    else:
        # For relative paths, prepend remote_root
        remote_path = f"{remote_root}/{input_path}".replace(os.path.sep, "/")
        rel_path = input_path

    print(f"Pulling {remote_path} from {host}...")
    
    # 1. Verify file exists on host
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
    try:
        run_command(["ssh"] + ssh_opts + [host, f"test -f {remote_path}"])
    except subprocess.CalledProcessError:
        print(f"Error: File '{remote_path}' not found on remote host.")
        sys.exit(1)
    
    # 2. Rsync file to hologram/
    local_dest = os.path.join(HOLOGRAM_DIR, rel_path)
    os.makedirs(os.path.dirname(local_dest), exist_ok=True)
    
    rsync_cmd = ["rsync", "-az", "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null", f"{host}:{remote_path}", local_dest]
    run_command(rsync_cmd)
    print(f"Synced to {local_dest}")

    # 2b. Enforce Overlay: Hide from Outside Wall
    # If the file exists in outside_wall, we must remove it so the hologram takes precedence.
    wall_dest = os.path.join(OUTSIDE_WALL_DIR, rel_path)
    if os.path.exists(wall_dest):
        try:
            # Ensure parent is writable if needed
            parent_dir = os.path.dirname(wall_dest)
            if not os.access(parent_dir, os.W_OK):
                 try:
                     os.chmod(parent_dir, 0o755)
                 except: 
                     pass
            
            os.remove(wall_dest)
            print(f"ðŸ‘» Ghosted (hidden) {wall_dest} from outside_wall")
        except OSError as e:
            print(f"Warning: Failed to hide {wall_dest} from outside_wall: {e}")
    
    # 3. Real Auto-Ghost (Dependency Syncing)
    print("Running Auto-Ghost logic...")
    
    # Use remote_root if available to find auto_ghost
    # We loaded config at start of do_pull
    remote_root = config.get('remote_root', '.')
    
    # If remote_root is absolute, try it first
    if remote_root.startswith("/"):
        auto_ghost_bin = f"{remote_root}/.mission/tools/bin/auto_ghost"
    else:
        # Fallback to dynamic discovery
        auto_ghost_bin = "$(git rev-parse --show-toplevel 2>/dev/null || echo '.')/.mission/tools/bin/auto_ghost"
        
    # Improved discovery: Try project tool, then global tool
    cmd_ghost = (
        f"ghost_bin=\"{auto_ghost_bin}\"; "
        f"if [ ! -f \"$ghost_bin\" ]; then ghost_bin=\"$HOME/.mission/tools/bin/auto_ghost\"; fi; "
        f"cd $(dirname {remote_path}) && $ghost_bin --full {remote_path}"
    )
    
    compile_context = None
    dependencies = []
    
    try:
        json_output = run_command(["ssh"] + ssh_opts + [host, cmd_ghost], capture_stderr=False)
        data = json.loads(json_output)
        
        # Handle both old (list) and new (dict) formats for backward compatibility
        if isinstance(data, list):
            dependencies = data
        elif isinstance(data, dict):
            dependencies = data.get("dependencies", [])
            compile_context = data.get("compile_context")
            
    except Exception as e:
        print(f"Warning: Auto-Ghost failed or returned invalid data: {e}")

    print(f"Auto-Ghost found {len(dependencies)} implicit dependencies.")
    
    # Update local compile database if context was provided
    update_local_compile_db(compile_context, dependencies)

    # Step 3b: Sync Dependencies to Outside Wall
    for dep_path in dependencies:
        if not dep_path.startswith("/"):
             continue 

        # Map to outside_wall
        # Remove leading slash to resolve against OUTSIDE_WALL_DIR
        rel_dep = dep_path.lstrip("/")
        dest_path = os.path.join(OUTSIDE_WALL_DIR, rel_dep)
        
        if os.path.exists(dest_path):
             os.chmod(dest_path, 0o644) # Make writable for rsync

        # Sync it
        print(f"  Ghosting: {dep_path}")
        os.makedirs(os.path.dirname(dest_path), exist_ok=True)
        ghost_rsync = ["rsync", "-az", "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null", f"{host}:{dep_path}", dest_path]
        try:
            run_command(ghost_rsync)
            # Enforce The Wall (Read-Only)
            os.chmod(dest_path, 0o444)
        except Exception as e:
            print(f"  Failed to ghost {dep_path}: {e}")



def find_build_context(hologram_root, start_path):
    """
    Finds the nearest build context (directory with Makefile or compile_commands.json)
    starting from start_path and walking up to hologram_root.
    Returns relative path from hologram_root, or None if no specific context found (root).
    """
    current = os.path.abspath(start_path)
    root = os.path.abspath(hologram_root)
    
    if not current.startswith(root):
        return None
        
    while True:
        # Check markers
        if os.path.exists(os.path.join(current, "Makefile")) or \
           os.path.exists(os.path.join(current, "compile_commands.json")) or \
           os.path.exists(os.path.join(current, ".ddd")):
            if current == root:
                return None # Root is default, no special context needed
            return os.path.relpath(current, root)
            
        parent = os.path.dirname(current)
        if not parent.startswith(root) or parent == current:
            break
        current = parent
        
    return None

def trigger_build(config, context_rel_path=None):
    """
    Triggers the remote build via DDD.
    Manages context switching by restarting the remote daemon if the context has changed.
    """
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]

    # Calculate Target Root
    if context_rel_path:
        remote_root_rel = remote_root.lstrip(os.path.sep)
        if context_rel_path.startswith(remote_root_rel):
             target_root = f"/{context_rel_path}".replace(os.path.sep, "/")
        else:
             target_root = f"{remote_root}/{context_rel_path}".replace(os.path.sep, "/")
    else:
        target_root = remote_root

    # Context State Management
    last_context = config.get('last_context')
    
    # Check if we need to restart
    if last_context != target_root:
        print(f"ðŸ”„ Context Switch Detected: {last_context} -> {target_root}")
        print("   Restarting Remote Daemon...")
        
        # 1. Kill existing session
        try:
             run_command(["ssh"] + ssh_opts + [host, "tmux kill-session -t mission_tower"], capture_stderr=False)
        except Exception:
             pass # Session might not exist, that's fine

        # 2. Launch with new PROJECT_ROOT
        # We need to find the launch_tower script relative to the *original* remote_root
        # because the tools are likely installed there, not in the subdir.
        # Assumption: Tools are in `remote_root/.mission`.
        
        launch_script = f"{remote_root}/.mission/tools/bin/launch_tower"
        
        # We start it detached in background via SSH? 
        # launch_tower starts tmux -d, so we just need to run the script.
        # We pass PROJECT_ROOT as env var.
        cmd = f"export PROJECT_ROOT='{target_root}'; {launch_script}"
        
        print(f"   Running: {cmd}")
        try:
             run_command(["ssh"] + ssh_opts + [host, cmd])
        except Exception as e:
             print(f"Error launching tower: {e}")
             # Don't crash, try to trigger anyway?
        
        # Update Config State
        config['last_context'] = target_root
        save_config(config)
        
        # Wait a moment for daemon to stabilize
        time.sleep(1)

    # 3. Trigger
    # The daemon is now running with PROJECT_ROOT = target_root.
    # So it looks for .ddd inside target_root.
    
    # NOTE: target_root might be a subdir.
    # So we touch target_root/.ddd/run/build.request
    
    build_req = f"{target_root}/.ddd/run/build.request"
    
    print(f"Triggering remote build at {build_req}...")
    
    # Ensure run directory exists
    req_dir = os.path.dirname(build_req)
    # Ignore errors (best effort)
    try:
         run_command(["ssh"] + ssh_opts + [host, f"mkdir -p {req_dir}"])
    except Exception:
         pass

    # Reliable Trigger: Remove then Touch (trigger on_created)
    run_command(["ssh"] + ssh_opts + [host, f"rm -f {build_req} && touch {build_req}"])

def find_project_root():
    current = os.path.abspath(os.getcwd())
    while True:
        if os.path.exists(os.path.join(current, CONFIG_FILE)):
            return current
        parent = os.path.dirname(current)
        if parent == current:
            break
        current = parent
    return None

def do_build(args):
    """Explicitly triggers the remote build."""
    config = load_config()
    
    project_root = find_project_root()
    if not project_root:
        print("Error: Could not find project root (.hologram_config).")
        sys.exit(1)
        
    hologram_abs = os.path.join(project_root, HOLOGRAM_DIR)
    
    # Determine Context
    if hasattr(args, 'context_from') and args.context_from:
        # Use provided file's directory
        start_path = os.path.dirname(os.path.abspath(args.context_from))
        print(f"Build Context Derived from: {args.context_from}")
    elif hasattr(args, 'sync') and args.sync:
        # If syncing a file, use that as context derivation too if not specified
        start_path = os.path.dirname(os.path.abspath(args.sync))
        print(f"Build Context Derived from: {args.sync}")
    else:
        # Fallback to CWD
        start_path = os.getcwd()

    # Pre-Build Sync
    if hasattr(args, 'sync') and args.sync:
        print(f"ðŸ”„ Syncing {args.sync} before build...")
        # Create a dummy args object for do_push
        class PushArgs:
            file = args.sync
        try:
            do_push(PushArgs, trigger=False)
        except Exception as e:
            print(f"âš ï¸ Warning: Sync failed: {e}")
            # Continue to build anyway? Or fail? Let's verify context at least.

    context_path = find_build_context(hologram_abs, start_path)
    
    trigger_build(config, context_path)
    print("âœ… Build triggered.")
    
    if hasattr(args, 'wait') and args.wait:
        print("â³ Waiting for build to complete...")
        # Determine log path
        remote_root = config.get('remote_root', '.')
        
        # NOTE: trigger_build MAY have updated last_context in config, but we need to reload it?
        # trigger_build calls save_config.
        config_reloaded = load_config()
        target_root = config_reloaded.get('last_context', remote_root)
        remote_log = f"{target_root}/.ddd/run/build.log"
        
        exit_code = monitor_build(config['host_target'], remote_log, stop_on_finish=True)
        sys.exit(exit_code)

def do_push(args, trigger=False):
    """Pushes a file back to the host."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    local_path = args.file

    # Check for CLI override
    if hasattr(args, 'trigger') and args.trigger:
        trigger = True
    
    project_root = find_project_root()
    if not project_root:
        print("Error: Could not find project root (.hologram_config).")
        sys.exit(1)

    abs_path = os.path.abspath(local_path)
    hologram_abs = os.path.join(project_root, HOLOGRAM_DIR)
    wall_abs = os.path.join(project_root, OUTSIDE_WALL_DIR)
    
    # 1. Check The Wall
    if abs_path.startswith(wall_abs):
        print("ðŸ›‘ VIOLATION: The Wall Breach Detected!")
        print(f"File {local_path} is in the Read-Only 'Outside Wall' zone.")
        print("You cannot push dependencies.")
        sys.exit(1)
        
    # 2. Check Valid Hologram File
    # Use os.path.commonpath to be safe?
    try:
        common = os.path.commonpath([hologram_abs, abs_path])
        if common != hologram_abs:
             print(f"Error: File {local_path} is not in the hologram directory.")
             sys.exit(1)
    except ValueError:
         print(f"Error: Paths on different drives or invalid.")
         sys.exit(1)
        
    # 3. Calculate remote path
    rel_path = os.path.relpath(abs_path, hologram_abs)
    # remote_root comes from config (loaded at start of do_push)
    
    # Handle absolute path mirroring (prevent double nesting)
    remote_root_stripped = remote_root.lstrip(os.path.sep)
    if rel_path.startswith(remote_root_stripped):
         remote_path = f"/{rel_path}".replace(os.path.sep, "/")
    else:
         remote_path = f"{remote_root}/{rel_path}".replace(os.path.sep, "/")
    
    print(f"Pushing {local_path} to {host}:{remote_path}...")
    
    # Ensure remote directory exists
    remote_dir = os.path.dirname(remote_path)
    if remote_dir and remote_dir != ".":
         ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
         # We ignore errors here in case it's a permission thing or exists, rsync will complain if it realy fails
         try:
             run_command(["ssh"] + ssh_opts + [host, f"mkdir -p {remote_dir}"])
         except Exception:
             pass

    rsync_cmd = ["rsync", "-az", "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null", local_path, f"{host}:{remote_path}"]
    run_command(rsync_cmd)
    
    if trigger:
        # Determine Context based on File Location
        context_path = find_build_context(hologram_abs, os.path.dirname(abs_path))
        trigger_build(config, context_path)
        print("Sync & Trigger complete.")
    else:
        print("Sync complete (No Trigger).")

def monitor_build(host, remote_log, stop_on_finish=False, mirror_log=None):
    """
    Monitors the remote build log.
    If stop_on_finish is True, returns 0 on SUCCESS, 1 on FAILURE.
    Includes robust reconnection logic.
    """
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
    
    while True:
        # Pre-Check (only for stop_on_finish)
        # If the build already finished while we were connecting/reconnecting, we might miss the live signal using tail -f.
        # So we check the tail of the file first.
        if stop_on_finish:
             try:
                check_cmd = ["ssh"] + ssh_opts + [host, f"tail -n 50 {remote_log} 2>/dev/null"]
                # Capture output, don't check=True because grep might fail? No, this is just tail.
                res = subprocess.run(check_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
                if res.returncode == 0:
                    for line in res.stdout.splitlines():
                        if "[MISSION COMPLETE]" in line or "BUILD_SUCCESS" in line:
                            print(f"âœ… [MISSION COMPLETE] (Detected in log history)", flush=True)
                            return 0
                        if "[MISSION FAILED]" in line or "BUILD_FAILURE" in line:
                            print(f"âŒ [MISSION FAILED] (Detected in log history)", flush=True)
                            return 1
             except Exception:
                 pass # Ignore pre-check errors, fall through to stream

        # Stream
        cmd = ["ssh"] + ssh_opts + [host, f"tail -F {remote_log} 2>/dev/null"]
        
        try:
            print(f"ðŸ“¡ Tuning into Mission Radio on {host}...", flush=True)
            process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, bufsize=1)
            
            while True:
                raw_line = process.stdout.readline()
                if not raw_line:
                    # EOF means process died (SSH disconnect?)
                    break
                
                # Mirror
                if mirror_log:
                    try:
                        with open(mirror_log, 'a') as f:
                            f.write(raw_line)
                    except Exception:
                        pass

                line = raw_line.strip()
                if not line:
                    continue
                    
                if line.startswith("[RADIO]"):
                    # Parse Signal
                    payload_str = line[len("[RADIO]"):].strip()
                    try:
                        payload = json.loads(payload_str)
                        event = payload.get("event")
                        msg = payload.get("message")
                        ts = payload.get("timestamp")
                        
                        if event == "BUILD_START":
                            print(f"\nðŸš€ [MISSION START] {ts}", flush=True)
                            print(f"   >> {msg}", flush=True)
                        elif event == "BUILD_SUCCESS":
                            print(f"âœ… [MISSION COMPLETE] {ts}", flush=True)
                            print(f"   >> {msg}\n", flush=True)
                            if stop_on_finish: return 0
                        elif event == "BUILD_FAILURE":
                            print(f"âŒ [MISSION FAILED] {ts}", flush=True)
                            print(f"   >> {msg}\n", flush=True)
                            if stop_on_finish: return 1
                        else:
                            print(f"â„¹ï¸  [RADIO] {event}: {msg}", flush=True)
                            
                    except json.JSONDecodeError:
                        print(f"âš ï¸  [RADIO CORRUPT] {line}", flush=True)
                else:
                    print(f"   [log] {line}", flush=True)
            
            # If we get here, the process ended (but wait didn't end).
            # Means SSH dropped.
            if process.poll() is None:
                process.terminate()
                
            print("âš ï¸ connection lost...", flush=True)
            
        except KeyboardInterrupt:
            print("\nðŸ‘‹ Radio off.")
            if stop_on_finish: 
                sys.exit(130) # Standard interrupt exit
            return
        except Exception as e:
            print(f"Error listening: {e}")
            
        if stop_on_finish:
            print("ðŸ”„ Reconnecting in 3s...", flush=True)
            time.sleep(3)
        else:
            return # If not waiting for finish (interactive listen), just exit on break? 
                   # Actually, legacy behavior was 'tail -F' which handles some retries, 
                   # but SSH wrapper breaks that. 
                   # For 'listen', user might prefer auto-reconnect too? 
                   # Let's keep it robust for both.
            print("ðŸ”„ Reconnecting in 3s...", flush=True)
            time.sleep(3)


def do_listen(args):
    """Listens to the Mission Radio (remote build logs)."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    target_root = config.get('last_context', remote_root)
    remote_log = f"{target_root}/.ddd/run/build.log"
    
    mirror_log = args.mirror_log if hasattr(args, 'mirror_log') else None
    
    monitor_build(host, remote_log, stop_on_finish=False, mirror_log=mirror_log)




def do_live(args):
    """Reflex + Impulse + Synthesis: Live Mode"""
    print("ðŸ§  The Synapse is active. (Live Mode)")
    
    # 1. Start Synthesis (The Radio) in a background thread
    print("ðŸ‘‚ Connecting to The Radio...")

    # Configure Log Mirroring to Hologram
    # We mirror the remote build log to local hologram/.ddd/run/build.log
    # This allows 'Local Smith' to see the logs as if they were local files.
    mirror_path = os.path.join(HOLOGRAM_DIR, ".ddd", "run", "build.log")
    os.makedirs(os.path.dirname(mirror_path), exist_ok=True)
    args.mirror_log = mirror_path
    
    print(f"ðŸªž Mirroring logs to {mirror_path}")

    radio_thread = threading.Thread(target=do_listen, args=(args,), daemon=True)
    radio_thread.start()
    
    # 2. Start Reflex (Watcher) & Impulse (Auto-Push)
    print("ðŸ‘ï¸  Watching hologram for changes...")
    
    # Simple timestamp-based polling
    poll_interval = 1.0 # seconds
    debounce_delay = 0.5
    
    last_mtimes = {}
    pending_changes = set()
    
    # Initial scan to populate mtimes
    if os.path.exists(HOLOGRAM_DIR):
        for root, dirs, files in os.walk(HOLOGRAM_DIR):
            for f in files:
                path = os.path.join(root, f)
                try:
                    last_mtimes[path] = os.path.getmtime(path)
                except OSError:
                    pass
    else:
        print(f"Warning: {HOLOGRAM_DIR} does not exist. Please run 'projector init' first.")
        # We continue anyway, as it might be created later or user might want to init in another terminal
                
    try:
        while True:
            time.sleep(poll_interval)
            
            # Scan for changes
            current_changes = set()
            if os.path.exists(HOLOGRAM_DIR):
                for root, dirs, files in os.walk(HOLOGRAM_DIR):
                    for f in files:
                        path = os.path.join(root, f)
                        try:
                            mtime = os.path.getmtime(path)
                            if path not in last_mtimes:
                                last_mtimes[path] = mtime
                                current_changes.add(path)
                            elif mtime > last_mtimes[path]:
                                last_mtimes[path] = mtime
                                current_changes.add(path)
                        except OSError:
                            pass
            
            if current_changes:
                # Add to pending and wait for debounce
                pending_changes.update(current_changes)
                print(f"âš¡ Reflex: Detected {len(current_changes)} changes. Debouncing...")
                time.sleep(debounce_delay)
                
                # Impulse: Push all pending changes
                files_to_push = list(pending_changes)
                pending_changes.clear()
                
                # Context logic for live mode?
                # The first file determines context? 
                # Or we sync all, then pick one for context?
                # Simple: Use the first one.
                first_file = None
                
                for f_path in files_to_push:
                    if os.path.exists(f_path): # Check again
                        if not first_file: first_file = f_path
                        print(f"ðŸŒŠ Impulse: Pushing {f_path}...")
                        # Create a dummy args object
                        class PushArgs:
                            file = f_path
                        
                        try:
                            # We don't trigger per file anymore
                            do_push(PushArgs(), trigger=False)
                        except SystemExit:
                             # do_push calls sys.exit(1) on failure, we must catch it
                            print(f"âš ï¸ Push failed for {f_path}")
                        except Exception as e:
                            print(f"âš ï¸ Error pushing {f_path}: {e}")
                            
                # Trigger ONCE after batch (if auto-build is enabled)
                if args.auto_build and first_file:
                    print("Triggering remote build for batch...")
                    # Determine context from first file
                    hologram_abs = os.path.abspath(HOLOGRAM_DIR)
                    context_path = find_build_context(hologram_abs, os.path.dirname(first_file))
                    trigger_build(load_config(), context_path)
                    print("âœ¨ Synced & Triggered.")
                else:
                    print("âœ¨ Synced (Use 'projector build' or run with --auto-build to trigger).")

    except KeyboardInterrupt:
        print("\nðŸ”Œ Disconnecting Synapse.")
        sys.exit(0)



def do_retract(args):
    """Retracts a file from the hologram (stops projecting it)."""
    input_path = args.file
    abs_path = os.path.abspath(input_path)
    
    config = load_config() # ensure we are in a hologram
    project_root = find_project_root()
    hologram_abs = os.path.join(project_root, HOLOGRAM_DIR)
    
    # 1. Validate Path
    try:
        common = os.path.commonpath([hologram_abs, abs_path])
        if common != hologram_abs:
             print(f"Error: File {input_path} is not in the hologram directory.")
             sys.exit(1)
    except ValueError:
         print(f"Error: Paths on different drives or invalid.")
         sys.exit(1)
         
    # 2. Remove File
    if os.path.exists(abs_path):
        os.remove(abs_path)
        print(f"ðŸ—‘ï¸  Retracted {input_path} from hologram.")
    else:
        print(f"Warning: File {input_path} does not exist locally.")
        
    # 2b. Restore to Outside Wall (if remote exists)
    # We stripped the hologram overlay, now we check if the base layer (remote) has it.
    try:
        rel_path = os.path.relpath(abs_path, hologram_abs)
        host = config['host_target']
        remote_root = config.get('remote_root', '.')
        
        # Calculate Remote Path
        remote_root_stripped = remote_root.lstrip(os.path.sep)
        if rel_path.startswith(remote_root_stripped):
             remote_path = f"/{rel_path}".replace(os.path.sep, "/")
        else:
             remote_path = f"{remote_root}/{rel_path}".replace(os.path.sep, "/")

        # Check Remote Existence
        ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
        check_cmd = ["ssh"] + ssh_opts + [host, f"test -f {remote_path}"]
        subprocess.check_call(check_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        
        # Restore
        wall_dest = os.path.join(project_root, OUTSIDE_WALL_DIR, rel_path)
        print(f"Restoring {wall_dest} from base layer...")
        
        os.makedirs(os.path.dirname(wall_dest), exist_ok=True)
        
        rsync_cmd = ["rsync", "-az", "-e", "ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null", f"{host}:{remote_path}", wall_dest]
        if run_command(rsync_cmd): # run_command returns stdout, truthy?
             pass 
             
        # Enforce Read-Only
        os.chmod(wall_dest, 0o444)
        print(f"ðŸ§± Restored to Outside Wall.")
        
    except subprocess.CalledProcessError:
        # Remote file doesn't exist, so nothing to restore
        pass
    except Exception as e:
        print(f"Warning: Failed to restore to outside_wall: {e}")
        
    # 3. Update compile_commands.json
    db_path = os.path.join(hologram_abs, "compile_commands.json")
    if os.path.exists(db_path):
        try:
            with open(db_path, 'r') as f:
                db = json.load(f)
            
            new_db = [e for e in db if os.path.abspath(e.get("file")) != abs_path]
            
            if len(db) != len(new_db):
                with open(db_path, 'w') as f:
                    json.dump(new_db, f, indent=2)
                print(f"cleaned compile_commands.json entry.")
        except Exception as e:
            print(f"Warning: Failed to update compile_commands.json: {e}")

def do_log(args):
    """Fetches the latest build log from the remote host."""
    config = load_config()
    host = config['host_target']
    remote_root = config.get('remote_root', '.')
    
    # Prefer last_context (where the daemon is actually running)
    target_root = config.get('last_context', remote_root)
    remote_log = f"{target_root}/.ddd/run/build.log"
    
    ssh_opts = ["-o", "StrictHostKeyChecking=no", "-o", "UserKnownHostsFile=/dev/null"]
    
    # Default to cat, but support --lines
    if args.lines:
        cmd = ["ssh"] + ssh_opts + [host, f"tail -n {args.lines} {remote_log} 2>/dev/null"]
    else:
        cmd = ["ssh"] + ssh_opts + [host, f"cat {remote_log} 2>/dev/null"]
        
    try:
        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        if result.returncode != 0:
            print(f"Error: Could not retrieve log from {host}:{remote_log}")
            sys.exit(1)
            
        print(result.stdout, end='') 
        
    except Exception as e:
        print(f"Error fetching log: {e}")
        sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description="Projector Agent: Manage Remote Brain Hologram")
    subparsers = parser.add_subparsers(dest="command", required=True)
    
    # Init
    p_init = subparsers.add_parser("init", help="Initialize hologram")
    p_init.add_argument("host_target", help="SSH target (user@host)")
    p_init.add_argument("--remote-root", help="Absolute path to remote repository root", default=".")
    p_init.set_defaults(func=do_init)
    
    # Pull
    p_pull = subparsers.add_parser("pull", help="Pull file from host")
    p_pull.add_argument("file", help="Remote absolute file path")
    p_pull.set_defaults(func=do_pull)
    
    # Push
    p_push = subparsers.add_parser("push", help="Push file to host")
    p_push.add_argument("file", help="Local file path")
    p_push.add_argument("--trigger", action="store_true", help="Trigger remote build after push")
    p_push.set_defaults(func=do_push)
    
    # Retract
    p_retract = subparsers.add_parser("retract", help="Stop projecting a file (remove locally)")
    p_retract.add_argument("file", help="Local file path")
    p_retract.set_defaults(func=do_retract)
    
    # Listen
    p_listen = subparsers.add_parser("listen", help="Listen to remote broadcast")
    p_listen.add_argument("--mirror-log", help="Path to mirror raw log file locally")
    p_listen.set_defaults(func=do_listen)
    
    # Log (Atomic)
    p_log = subparsers.add_parser("log", help="Fetch remote build log (One-shot)")
    p_log.add_argument("-n", "--lines", type=int, help="Number of lines to tail")
    p_log.set_defaults(func=do_log)
    
    # Build
    p_build = subparsers.add_parser("build", help="Trigger remote build manually")
    p_build.add_argument("--context-from", help="Derive build context from this file path")
    p_build.add_argument("--sync", help="Synchronize specific file before building")
    p_build.add_argument("--wait", action="store_true", help="Wait for build completion and stream logs")
    p_build.set_defaults(func=do_build)
    
    # Live
    p_live = subparsers.add_parser("live", help="Live mode (Watch + Push + Listen)")
    p_live.add_argument("--auto-build", action="store_true", help="Enable automatic build triggering on file changes")
    p_live.set_defaults(func=do_live)
    
    args = parser.parse_args()
    args.func(args)

if __name__ == "__main__":
    main()
